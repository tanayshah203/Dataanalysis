{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Vehicle Loan Prediction Machine Learning Model\n",
    "\n",
    "# Chapter 2 - Load and Clean the Data\n",
    "\n",
    "## Lesson 1 - Getting Started\n",
    "\n",
    "In this lesson, we will import the required libraries and load the data!\n",
    "\n",
    "### Import Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "source": [
    "### Loading the Data\n",
    "\n",
    "- Our vehicle loan data is provided in csv format \n",
    "- We can load it into python as a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) with [pd.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)\n",
    "- Each loan in our dataset has a UNIQUEID which we will use as the row index\n",
    "\n",
    "First, let's use pandas to load our loan data and store it in a variable called loan_df\n",
    "\n",
    "- Replace ‘../data/vehicle_loans.csv’ with your local file path and name"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = pd.read_csv('../data/vehicle_loans.csv', index_col='UNIQUEID')"
   ]
  },
  {
   "source": [
    "We can use [df.head](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) to get the first n rows from a DataFrame\n",
    "\n",
    "- defaults to bring out the first 5 rows"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.head()"
   ]
  },
  {
   "source": [
    "## Lesson 2 - First Look\n",
    "\n",
    "Now that we have loaded the data, let's take a closer Look\n",
    "\n",
    "### Rows and Columns\n",
    "\n",
    "- How many data points do we have?\n",
    "- How many attributes are there?\n",
    "- We can get the dimensions of our DataFrame using [df.shape](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.shape"
   ]
  },
  {
   "source": [
    "- The shape property of a dataframe contains a tuple with the dimensions of the dataframe\n",
    "- A tuple is an ordered immutable (unchangeable) collection \n",
    "- Tuple elements can be accessed using indexes, like lists"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows: \", loan_df.shape[0])\n",
    "print(\"Number of columns: \", loan_df.shape[1])"
   ]
  },
  {
   "source": [
    "Ok, so we have 233154 data points each with 40 variables\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Variable Types\n",
    "\n",
    "- Before we go any further it is important to understand the type of data stored in our columns\n",
    "- Pandas [df.info()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) shows us both the data type and the not null count for each column\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.info()"
   ]
  },
  {
   "source": [
    "Now we know we have 3 data types:\n",
    "- int64 (whole number)\n",
    "- float64 (floating point number)\n",
    "- object (string or non-numeric)\n",
    "\n",
    "Straight away there are some interesting things,\n",
    "\n",
    "DATE_OF_BIRTH, EMPLOYMENT_TYPE, DISBURSAL_DATE, PERFORM_CNS_SCORE_DESCRIPTION, AVERAGE_ACCT_AGE and CREDIT_HISTORY_LENGTH are all object data types, meaning they contain non-numeric values such as strings or dates. \n",
    "\n",
    "EMPLOYMENT_TYPE has some missing values\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Date Range\n",
    "\n",
    "DISBURSAL_DATE contains the date the agreed loan amount was transferred to the applicant, let's use it to get an idea of the timeframe covered by the data \n",
    "\n",
    "The first step is to convert DISBURSAL_DATE to a datetime\n",
    "- We can use [pd.to_datetime](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) to convert an entire column to datetime \n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['DISBURSAL_DATE'] = pd.to_datetime(loan_df['DISBURSAL_DATE'])"
   ]
  },
  {
   "source": [
    "Now we can use [min](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.min.html) and [max] to look for the first and last loan disbursals in our data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum Disbursal Date: \", loan_df['DISBURSAL_DATE'].max())\n",
    "print(\"Minium Disbursal Date: \", loan_df['DISBURSAL_DATE'].min())"
   ]
  },
  {
   "source": [
    "We can do mathematical operations on datetimes to get the difference in days"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Timespan of Data Set: \", loan_df['DISBURSAL_DATE'].max() - loan_df['DISBURSAL_DATE'].min())"
   ]
  },
  {
   "source": [
    "### Now we know\n",
    "\n",
    "- Our dataset has information for 233154 loans \n",
    "- There are 40 variables \n",
    "- The data covers loans over 336 days between January and December 2018\n",
    "\n",
    "More detailed exploratory analysis will be covered in the next chapter\n",
    "\n",
    "For now, let's move on to look at what we are actually trying to predict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Lesson 3 - Target Variable\n",
    "\n",
    "### What is the target variable?\n",
    "\n",
    "- Variable we are trying to predict\n",
    "- LOAN_DEFAULT is our target variable so lets investigate it further\n",
    "\n",
    "\n",
    "### Explore the Target Variable\n",
    "- How many people defaulted on their loans?\n",
    "- To count the frequency of unique values in a dataframe column we can use [value_counts](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['LOAN_DEFAULT'].value_counts()"
   ]
  },
  {
   "source": [
    "Great! We can see that out of our 233154 loans, there are 50611 which defaulted\n",
    "\n",
    "The 'normalize' parameter lets us use value_counts to get a percentage"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['LOAN_DEFAULT'].value_counts(normalize=True)"
   ]
  },
  {
   "source": [
    "The rate of defaulted loans is about 21.7% keep this in mind!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Visualize the Target Variable\n",
    "\n",
    "Just for good measure lets visualize our target variable using the [countplot](https://seaborn.pydata.org/generated/seaborn.countplot.html) function from seaborn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"LOAN_DEFAULT\", data=loan_df)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Lesson 4 - Missing Values\n",
    "\n",
    "We saw earlier that our dataset contains some missing values, specifically for the EMPLOYMENT_TYPE column.\n",
    "\n",
    "### Identifying Missing Data\n",
    "\n",
    "Time to investigate what we saw earlier by identifying the columns with missing values\n",
    "\n",
    "Using [df.isnull](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html) we can find those columns which have at least one null value\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.isnull()"
   ]
  },
  {
   "source": [
    "[df.isnull](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html) outputs a DataFrame with a boolean value in each cell indicating the presence of a null value\n",
    "\n",
    "We can combine [df.isnull](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html) with [df.any](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.any.html) to get a list of all columns with at least one missing value"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.isnull().any()"
   ]
  },
  {
   "source": [
    "As expected, the only column with any null values is EMPLOYMENT_TYPE\n",
    "\n",
    "Combine [df.isnull](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.isnull.html) with [df.sum](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sum.html) to get a count of missing values for all columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.isnull().sum()"
   ]
  },
  {
   "source": [
    "### Handling Missing Values\n",
    "\n",
    "Ok, we can see that EMPLOYMENT_TYPE has 7661 missing values so we should take a closer look,"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### EXERCISE - Explore EMPLOYMENT_TYPE\n",
    "\n",
    "- Find out how many unique values are in the column\n",
    "- Hint: Remember how we used [value_counts](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) and [catplot](https://seaborn.pydata.org/generated/seaborn.catplot.html) to explore the target variable"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### SOLUTION\n",
    "\n",
    "- First, we use [value_counts](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) to print 'EMPLOYMENT_TYPE' unique values with their counts \n",
    "- Next, we visualize this grouping using [catplot](https://seaborn.pydata.org/generated/seaborn.catplot.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loan_df['EMPLOYMENT_TYPE'].value_counts())\n",
    "sns.countplot(x=\"EMPLOYMENT_TYPE\", data=loan_df)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "### Handling Missing Values - Continued\n",
    "\n",
    "Note that EMPLOYMENT_TYPE contains two unique values, 'Salaried' and 'Self Employed'\n",
    "\n",
    "Since there are relatively few missing values (7661) we can populate them with a placeholder 'Missing' using pandas [fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = loan_df.fillna(value={'EMPLOYMENT_TYPE' : 'Missing'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loan_df['EMPLOYMENT_TYPE'].value_counts())\n",
    "sns.countplot(x=\"EMPLOYMENT_TYPE\", data=loan_df)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "We can see that the 7661 missing values for employment type have been labelled with the string 'Missing'"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Lesson 5 - Dealing with Dates\n",
    "\n",
    "- We have two date columns, DISBURSAL_DATE and DATE_OF_BIRTH\n",
    "- These should be transformed into a more algorithm friendly format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df[['DISBURSAL_DATE', 'DATE_OF_BIRTH']].sample(10)"
   ]
  },
  {
   "source": [
    "### Calculating Age \n",
    "\n",
    "- Intuitively it is fair to assume that age is associated with loan default risk \n",
    "- However, we currently do not have a measure of age, only date of birth\n",
    "\n",
    "\n",
    "### EXERCISE \n",
    "\n",
    "- Can you create a new column 'AGE' based on the existing DATE_OF_BIRTH and DISUBURAL_DATE columns\n",
    "- HINT: use [pd.to_datetime](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) to convert from string to datetime"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### SOLUTION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['DATE_OF_BIRTH'] = pd.to_datetime(loan_df['DATE_OF_BIRTH'])\n",
    "loan_df['DISBURSAL_DATE'] = pd.to_datetime(loan_df['DISBURSAL_DATE'])\n",
    "\n",
    "#calculate their age at time of disbursal\n",
    "loan_df['AGE'] = loan_df['DISBURSAL_DATE'] - loan_df['DATE_OF_BIRTH']\n",
    "loan_df['AGE'] = loan_df['AGE'] // np.timedelta64(1, 'Y')\n",
    "\n",
    "#Inspect the results\n",
    "print(loan_df[['DATE_OF_BIRTH', 'AGE', 'DISBURSAL_DATE']].sample(n=5))"
   ]
  },
  {
   "source": [
    "### SOLUTION - EXPLAINED\n",
    "\n",
    "- First, make sure that DATE_OF_BIRTH and DISBURSAL_DATE are datetimes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['DATE_OF_BIRTH'] = pd.to_datetime(loan_df['DATE_OF_BIRTH'])\n",
    "loan_df['DISBURSAL_DATE'] = pd.to_datetime(loan_df['DISBURSAL_DATE'])\n",
    "\n",
    "print(\"DATE_OF_BIRTH variable type: \", loan_df['DATE_OF_BIRTH'].dtypes)\n",
    "print(\"DISBURSAL_DATE variable type: \", loan_df['DISBURSAL_DATE'].dtypes)"
   ]
  },
  {
   "source": [
    "- now calculate the difference between DISBURSAL_DATE and DATE_OF_BIRTH"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['AGE'] = loan_df['DISBURSAL_DATE'] - loan_df['DATE_OF_BIRTH']\n",
    "loan_df['AGE'].sample(n=10)"
   ]
  },
  {
   "source": [
    "- now we have the age in days \n",
    "- divide age by 1 year\n",
    "- // operator performs division and rounds down to the nearest whole number"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['AGE'] = loan_df['AGE'] // np.timedelta64(1, 'Y')"
   ]
  },
  {
   "source": [
    "- sanity check our output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loan_df[['DATE_OF_BIRTH', 'AGE', 'DISBURSAL_DATE']].sample(n=5))"
   ]
  },
  {
   "source": [
    "### Disbursal Month\n",
    "\n",
    "- At this point, we do not know how the disbursal date might be related to loan defaults\n",
    "- We want to explore this relationship so need to convert to a numeric representation\n",
    "\n",
    "### EXERCISE \n",
    "\n",
    "- Can you create a new column 'DISBURSAL_MONTH' to store the disbursal month as an integer\n",
    "- HINT: pandas [dt](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.html) allows us to extract month as an integer from a datetime"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### SOLUTION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['DISBURSAL_MONTH'] = loan_df['DISBURSAL_DATE'].dt.month\n",
    "loan_df['DISBURSAL_MONTH'].value_counts()"
   ]
  },
  {
   "source": [
    "As we can see, the distribution of loan disbursals is not even across all months, we will look into this in future lessons but for now, we can drop the disbursal date column.\n",
    "\n",
    "We can now [drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html) DISBURSAL_DATE and DATE_OF_BIRTH from our data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = loan_df.drop(['DISBURSAL_DATE', 'DATE_OF_BIRTH'], axis=1)"
   ]
  },
  {
   "source": [
    "## Lesson 6 - Fix the Strings\n",
    "\n",
    "- AVERAGE_ACCT_AGE and CREDIT_HISTORY_LENGTH were also strings \n",
    "- Column names suggest they should be numeric, let's take a look "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### String Fields\n",
    "\n",
    "- Can select a subset of DataFrame columns by passing in a list of column names,  [indexing](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)\n",
    "- [df.sample](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html) can be used to pull a random sample of n rows"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df[['CREDIT_HISTORY_LENGTH', 'AVERAGE_ACCT_AGE']].sample(n=10)"
   ]
  },
  {
   "source": [
    "Both columns contain measures of time in the format \"0yrs 0mon\"\n",
    "\n",
    "This string representation is not useful for analysis or prediction so let's convert it into a number"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### String Manipulation\n",
    "\n",
    "The current format of AVERAGE_ACCT_AGE and CREDIT_HISTORY_LENGTH is not useful\n",
    "\n",
    "### EXERCISE\n",
    "\n",
    "- Can you create a new column 'AVERAGE_ACCT_AGE_MONTHS' to store the average account age as an integer of months?\n",
    "- HINT: First think about how to extract numbers from the String\n",
    "- HINT: [df['COL_NAME'].map()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) can be used to perform functions/operations on an entire column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### SOLUTION \n",
    "\n",
    "### Step 1 - Create a function which can calculate the total number of months based on a list of input strings\n",
    "\n",
    "The calc_months function simply takes the list of two numbers stored in AVERAGE_ACCT_AGE_MONTHS\n",
    "\n",
    "- We recognize that the first number is the number of years \n",
    "- The second is the number of months \n",
    "- Simple calculation to get the total number of years"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_months(str_list):  \n",
    "    years = int(str_list[0])\n",
    "    months = int(str_list[1])\n",
    "\n",
    "    num_months = (years * 12) + months\n",
    "    return num_months"
   ]
  },
  {
   "source": [
    "### Step 2 - Extract the relevant numbers from the original string data\n",
    "\n",
    "Pandas str.findall can be used to find all instances of a string within a column\n",
    "\n",
    "the '\\d+' is a regular expression which finds integers in a string\n",
    "\n",
    "regular expressions can be used to identify and extract patterns in strings\n",
    "all you need to know for know is that loan_df'AVERAGE_ACCT_AGE'.str.findall('\\d+') returns a list of all the numbers in the string stored in the 'AVERAGE_ACCT_AGE' column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['AVERAGE_ACCT_AGE_MONTHS'] = loan_df['AVERAGE_ACCT_AGE'].str.findall('\\d+')\n",
    "print(loan_df['AVERAGE_ACCT_AGE_MONTHS'].sample(n=10))"
   ]
  },
  {
   "source": [
    "This creates a column 'AVERAGE_ACCT_AGE_MONTHS' which stores a list of numbers where the first item represents the number of years and the second represents the number of months\n",
    "\n",
    "### Step 3 - Use map to perform calc_months across all rows\n",
    "\n",
    "Use [map](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html) to apply a function which calculates the total number of months for each row in the dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['AVERAGE_ACCT_AGE_MONTHS'] = loan_df['AVERAGE_ACCT_AGE_MONTHS'].map(calc_months)"
   ]
  },
  {
   "source": [
    "### Step 4 - Inspect the results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loan_df[['AVERAGE_ACCT_AGE_MONTHS', 'AVERAGE_ACCT_AGE']].sample(n=10))"
   ]
  },
  {
   "source": [
    "### More String Manipulation\n",
    "\n",
    "- Great, now we have fixed AVERAGE_ACCT_AGE how about CREDIT_HISTORY_LENGTH?\n",
    "- We could simply copy and paste our solution from the previous exercise\n",
    "- How about if we had 20 columns to fix instead of 2?\n",
    "\n",
    "### EXERCISE\n",
    "\n",
    "- Convert your solution to the previous exercise into a function and use it to fix CREDIT_HISTORY_LENGTH"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### SOLUTION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str_to_months(col_name):\n",
    "    new_col = col_name + '_MONTHS'\n",
    "    loan_df[new_col] = loan_df[col_name].str.findall('\\d+')\n",
    "    loan_df[new_col] = loan_df[new_col].map(calc_months)\n"
   ]
  },
  {
   "source": [
    "Run the function and check the output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_str_to_months('CREDIT_HISTORY_LENGTH')\n",
    "loan_df[['CREDIT_HISTORY_LENGTH_MONTHS', 'CREDIT_HISTORY_LENGTH']].sample(n=5)"
   ]
  },
  {
   "source": [
    "Looks good, remember to drop the columns you don't need"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = loan_df.drop(['AVERAGE_ACCT_AGE', 'CREDIT_HISTORY_LENGTH'], axis=1)"
   ]
  },
  {
   "source": [
    "### Conclusion \n",
    "\n",
    "- We have now cleaned all of the ‘object’ columns except ‘PERFORM_CNS_SCORE_DESCRIPTION’\n",
    "- Use [value_counts](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) to have a quick look at this "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['PERFORM_CNS_SCORE_DESCRIPTION'].value_counts()"
   ]
  },
  {
   "source": [
    "Looks like a categorical field, we will look at this again in the next chapter\n",
    "\n",
    "We are now finished with our data clean up, let's save our clean data to a new csv using [df.to_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.to_csv('../data/vehicle_loans_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}