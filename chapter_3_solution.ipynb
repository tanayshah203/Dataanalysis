{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"chapter_3_solution.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"qzMf_GAEajv2"},"source":["# Vehicle Loan Prediction Machine Learning Model\n","\n","# Chapter 3 - Exploratory Data Analysis\n","\n","## Lesson 1 - Introduction to EDA\n","\n"]},{"cell_type":"markdown","metadata":{"id":"V8D_bNI_ajv4"},"source":["### First things first\n","\n","Remember to load the libraries and import the cleaned data we created last time"]},{"cell_type":"code","metadata":{"id":"UGgRM8wLajv5"},"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJJDCSVBajv6"},"source":["loan_df = pd.read_csv('../data/vehicle_loans_clean.csv', index_col='UNIQUEID')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NOGTbq2Vajv6"},"source":["Use the [df.info](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html) function to remind ourselves what variables we are dealing with"]},{"cell_type":"code","metadata":{"id":"BsgzPJboajv6"},"source":["loan_df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WG17343dajv7"},"source":["- We still have 40 columns\n","- Our new columns; ‘AGE’, ‘DISBURSAL_MONTH’, ‘AVERAGE_ACCT_AGE_MONTHS’ and ‘CREDIT_HISTORY_LENGTH_MONTHS’ are shown at the bottom of the list\n","- Start to think about how different columns might be related to both the target variable and each other"]},{"cell_type":"markdown","metadata":{"id":"3CkP4iuTajv7"},"source":["### Unique Values \n","\n","- A good starting for exploratory analysis is to look at the number of unique values in each column\n","- Pandas [df.nunique](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.nunique.html) provides a quick and easy way to count column-wise unique values"]},{"cell_type":"code","metadata":{"id":"VIBbE-f8ajv8"},"source":["loan_df.nunique()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PuvRC9EJajv8"},"source":["Do you notice anything interesting?\n","- MOBILE_AVL_FLAG has only one unique value! \n","\n","Let's look in more detail to be sure "]},{"cell_type":"code","metadata":{"id":"5F1eUSHsajv9"},"source":["loan_df['MOBILENO_AVL_FLAG'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eqRxKMSdajv9"},"source":["- Every row contains the value 1 \n","- It has no predictive value so we can drop it"]},{"cell_type":"code","metadata":{"id":"L63hkbyaajv9"},"source":["loan_df = loan_df.drop(['MOBILENO_AVL_FLAG'], axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1xTaxgCSajv9"},"source":["## Lesson 2 -  What's in the IDs?\n","\n","Since they are near the top of our list of columns, let's take a look at the 6 Id fields.\n","\n","- BRANCH_ID: Branch where the loan was disbursed\n","- SUPPLIER_ID: Vehicle Dealer where the loan was disbursed \n","- MANUFACTURER_ID: Vehicle manufacturer(Hero, Honda, TVS etc.)\n","- CURRENT_PINCODE_ID: Current pincode of the customer\n","- STATE_ID: State of disbursement\n","- EMPLOYEE_CODE_ID: Employee of the organization who logged the disbursement"]},{"cell_type":"code","metadata":{"id":"dn9BAdJ-ajv-"},"source":["loan_df[['SUPPLIER_ID', 'CURRENT_PINCODE_ID', 'EMPLOYEE_CODE_ID', 'BRANCH_ID', 'STATE_ID', 'MANUFACTURER_ID']].sample(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A8BQ53Aiajv-"},"source":["These six fields contain numeric data, but really they represent categorical, underordered information. For example, we cannot say things like manufacturer id 1 < 2, or state id 1 = 3 - 2. \n","\n","Id fields with large numbers of unique values will introduce complexity into our predictive model. Therefore, we will drop them from the dataset. "]},{"cell_type":"code","metadata":{"id":"UWUy_JZVajv-"},"source":["loan_df = loan_df.drop(['SUPPLIER_ID', 'CURRENT_PINCODE_ID', 'EMPLOYEE_CODE_ID', 'BRANCH_ID'], axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"269kPiu2ajv-"},"source":["### A Closer Look \n","\n","### EXERCISE \n","\n","- Pick one of the two remaining Id columns and write some code to investigate its unique values\n","- HINT: We did this with ‘LOAN_DEFAULT’ in chapter 2\n"]},{"cell_type":"markdown","metadata":{"id":"qtZa4r2Fajv-"},"source":["### SOLUTION\n","\n","- use [value_counts](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) to get manufacturer frequencies \n","- include the normalize parameter to look at the percentages \n","- plot using [catplot](https://seaborn.pydata.org/generated/seaborn.catplot.html)"]},{"cell_type":"code","metadata":{"id":"7BWoLbkwajv_"},"source":["print(loan_df['MANUFACTURER_ID'].value_counts())\n","print(loan_df['MANUFACTURER_ID'].value_counts(normalize=True))\n","sns.countplot(x=\"MANUFACTURER_ID\", data=loan_df)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n-0BaSPOajv_"},"source":["### Dig a little deeper\n","\n","- It is important to understand how a particular variable is spread \n","- However, we are really interested in its relationship to the target variable!\n","\n","### Group By\n","\n","- Pandas provides a very useful [df.groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) function which can be used to group DataFrame rows according to a single column or group of columns\n","- Similar to the GROUP BY statement in SQL\n","- Returns a group by object on which we can perform aggregations such as sum, min and max\n","- We can select subsets of columns to interrogate the data further"]},{"cell_type":"markdown","metadata":{"id":"QAeP8cztajv_"},"source":["### Group by examples"]},{"cell_type":"code","metadata":{"id":"dED89Wpiajv_"},"source":["loan_df.groupby('MANUFACTURER_ID')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B6KreRmgajwA"},"source":["- Pure output of groupby not that useful\n","- Let’s try an aggregation"]},{"cell_type":"code","metadata":{"id":"LS2iviPMajwA"},"source":["loan_df.groupby('MANUFACTURER_ID').max()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kiD_Qcf3ajwA"},"source":["- Ok, now we can see the max value for each column for every ‘MANUFACTURER_ID’\n","- We can select subsets of the groups and perform operations on them\n"]},{"cell_type":"code","metadata":{"id":"neNtWsXGajwA"},"source":["loan_df.groupby('MANUFACTURER_ID')['LOAN_DEFAULT'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oim20V9aajwA"},"source":["We can also use [unstack](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.unstack.html), to give a more readable output\n","\n","- [unstack](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.unstack.html) let's us pivot the output of our groupby to give us columns for the unique values of loan default\n","- The level parameter is used to set the column on which to pivot. In our case want to use the LOAN_DEFAULT column which is the last labelled column in our output, so we set level to -1 to indicate we want to pivot on the last column "]},{"cell_type":"code","metadata":{"id":"brKzBMo9ajwB"},"source":["loan_df.groupby('MANUFACTURER_ID')['LOAN_DEFAULT'].value_counts().unstack(level=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cvKn6wSPajwB"},"source":["### Visualized Groupings\n","\n","- Now we can start to see how loan defaults are distributed within manufacturer groups\n","- Remember the normalize parameter from value_counts?"]},{"cell_type":"code","metadata":{"id":"etXCwLR8ajwB"},"source":["loan_df.groupby('MANUFACTURER_ID')['LOAN_DEFAULT'].value_counts(normalize=True).unstack(level=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i_uAcHpPajwB"},"source":["- Looks like loans for some manufacturers default at higher rates than others!\n","- Cars from manufacturer 48 defaulted most frequently. *With the exception of 153 which only had 12 total loans which is not enough data to give us solid insight*\n","- Seaborn [catplot](https://seaborn.pydata.org/generated/seaborn.catplot.html) to visualize the groupings\n","- We are using catplot rather than countplot as it allows us to group together data with the hue parameter\n","- x parameter is the main x-axis variable \n","- hue is the column we want to create sub-groups on"]},{"cell_type":"code","metadata":{"id":"SvMlKt8DajwB"},"source":["sns.catplot(data=loan_df,kind='count',x='MANUFACTURER_ID',hue='LOAN_DEFAULT')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"arMvROFfajwC"},"source":["## Lesson 3 - Reusable EDA\n","\n","In the previous lesson, we took a more detailed look at ‘MANUFACTURER_ID’\n","\n","We still have 4 categorical variables to investigate!\n","- EMPLOYMENT_TYPE: Employment Type of the customer\n","- PERFORM_CNS_SCORE_DESCRIPTION: Bureau score description \n","- STATE_ID: State of disbursement \n","- DISBURSAL_MONTH: The month in which the loan was disbursed\n","\n","We could copy and paste our steps from the previous lesson\n","\n","As a general rule of thumb in programming, we want to avoid repeating ourselves"]},{"cell_type":"markdown","metadata":{"id":"fz13H8XOajwC"},"source":["### EXERCISE \n","\n","- Write a function to perform the steps from lesson 2 for any column \n","- Use this to explore the remaining categorical variables and think about their relationships with the target \n"]},{"cell_type":"markdown","metadata":{"id":"a28Z2wKRajwC"},"source":["### SOLUTION\n","\n","- Use print statements to make output readable "]},{"cell_type":"code","metadata":{"id":"uDK6hzT4ajwC"},"source":["def explore_categorical(col_name):   \n","    print(\"{0} Summary\".format(col_name))\n","    print(\"\\n\")\n","\n","    print(\"{0} Counts\".format(col_name))\n","    print(loan_df[col_name].value_counts())\n","    print(\"\\n\")\n","\n","    print(\"{0} Ratio\".format(col_name))\n","    print(loan_df[col_name].value_counts(normalize=True))\n","    print(\"\\n\")\n","\n","    print(\"{0} Default Counts\".format(col_name))\n","    print(loan_df.groupby(col_name)['LOAN_DEFAULT'].value_counts().unstack(level=-1))\n","    print(\"\\n\")\n","\n","    print(\"{0} Default Ratio\".format(col_name))\n","    print(loan_df.groupby(col_name)['LOAN_DEFAULT'].value_counts(normalize=True).unstack(level=-1))\n","    print(\"\\n\")\n","\n","    sns.catplot(data=loan_df,kind='count',x=col_name,hue='LOAN_DEFAULT')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BfpcGIzOajwC"},"source":["Lets our explore_categorical function to look at DISBURSAL_MONTH"]},{"cell_type":"code","metadata":{"id":"76fzhhVtajwC"},"source":["explore_categorical(\"DISBURSAL_MONTH\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g1PE2RSAajwC"},"source":["- The vast majority of loans were disbursed in August, September and October \n","- Loans disbursed in October had the highest rate of default ~24%"]},{"cell_type":"markdown","metadata":{"id":"uGjcmLJCajwD"},"source":["## Lesson 4 - Continuous Variables \n","\n","So far in this chapter, we have seen how to investigate categorical data but\n","we have a number of continuous variables to deal with also!\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"qMq-LzCHajwD"},"source":["### Summary Statistics\n","\n","- The first port of call for exploring continuous variables\n","- Look at the mean, median, IQR, standard deviation and min/max to get an idea of the range of data and how it is distributed\n","- Pandas gives us the [describe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) function which generates statistical summaries!"]},{"cell_type":"code","metadata":{"id":"3faFf3bGajwD"},"source":["loan_df[\"AGE\"].describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5f1SBRlajwD"},"source":["Some things to note here\n","\n","- The mean is 33.9\n","- The medium is 32 (medium is smaller, could the distribution be skewed a little)\n","- Max is far bigger than 3rd Q, probably has a right tail\n","- Min of 17 and Max of 69, these are reasonable so no erroneous outliers "]},{"cell_type":"markdown","metadata":{"id":"STcf1evAajwD"},"source":["### Box Plots and Distributions\n","\n","- As with most things, summary statistics are often easier to interpret when visualized\n","- Luckily, seaborn makes this easy for us with its [boxplot](https://seaborn.pydata.org/generated/seaborn.boxplot.html) and [distplot](https://seaborn.pydata.org/generated/seaborn.distplot.html) functions"]},{"cell_type":"code","metadata":{"id":"ibP6zie1ajwD"},"source":["sns.boxplot(x=\"AGE\", data=loan_df)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GE2Jpp5rajwD"},"source":["As suspected, there is a right tail. Now we can use the [distplot](https://seaborn.pydata.org/generated/seaborn.distplot.html) function from seaborn to look at the distribution\n","\n"]},{"cell_type":"code","metadata":{"id":"BoDUfpUzajwD"},"source":["sns.distplot(loan_df['AGE'], hist=False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"apQVJbk8ajwE"},"source":["### Grouped Summaries\n","\n","- Just as we did for the categorical variables, we want to explore the relationship between our continuous variables and the LOAN_DEFAULT column\n","- Remember [groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)? We can combine this with the [describe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) function to generate grouped summary statistics!"]},{"cell_type":"code","metadata":{"id":"3iArPIcAajwE"},"source":["loan_df.groupby('LOAN_DEFAULT')['AGE'].describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f2I-ZufcajwE"},"source":["Ok, looks like the people who defaulted were generally younger. \n","\n","We can use sns boxplot to visualize this"]},{"cell_type":"code","metadata":{"id":"cdxd6WKlajwE"},"source":["sns.boxplot(x='AGE', y='LOAN_DEFAULT', data=loan_df, orient=\"h\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9pfRnMcjajwE"},"source":["The distribution of AGE within the group of people who defaulted was marginally younger! "]},{"cell_type":"markdown","metadata":{"id":"jPDw2RiHajwE"},"source":["### EXERCISE \n","\n","- Using the steps we have performed to explore ‘AGE’, write a function that can be used to explore other continuous variables\n","- Pick a few more continuous variables to explore and use your function to investigate them!\n","- Keep a note of your findings"]},{"cell_type":"markdown","metadata":{"id":"bQEK3aP9ajwE"},"source":["### SOLUTION"]},{"cell_type":"code","metadata":{"id":"t7moOpwKajwF"},"source":["def explore_continuous(col_name):\n","    #print statistical summary\n","    print(\"{0} Summary\".format(col_name))\n","    print(\"\\n\")\n","    print(loan_df[col_name].describe())\n","    print(\"\\n\")\n","\n","    #Look at boxplot\n","    sns.boxplot(x=col_name, data=loan_df)\n","    plt.show()\n","\n","    #Look at the distribution\n","    sns.distplot(loan_df[col_name], hist=False)\n","    plt.show()\n","\n","    #Now lets look deeper by grouping with the target variable \n","    print(\"{0} Grouped Summary\".format(col_name))\n","    print(\"\\n\")\n","    print(loan_df.groupby('LOAN_DEFAULT')[col_name].describe())\n","\n","    #look at grouped boxplot \n","    sns.boxplot(x=col_name, y='LOAN_DEFAULT', data=loan_df, orient=\"h\")\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B1BVqEoRajwF"},"source":["Let's use our new function to look at the DISBURSED_AMOUNT column"]},{"cell_type":"code","metadata":{"id":"yZ39Au8sajwF"},"source":["explore_continuous('DISBURSED_AMOUNT')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TQHXR0MvajwF"},"source":["Things to note \n","\n","- There are some huge outliers here, we will cover techniques for dealing with them in a later lesson \n","- Generally, the disbursed amount for defaulted loans was larger, or at least the distribution ranges over larger values "]},{"cell_type":"markdown","metadata":{"id":"y3fLB9UIajwF"},"source":["## Lesson 5 - Binary Variables & Conclusion\n","\n","You may have noticed that our data contains several columns with the underscore _FLAG\n","\n","- MOBILENO_AVL_FLAG: if Mobile no. was shared by the customer then flagged as 1\n","- AADHAR_FLAG: if aadhar was shared by the customer then flagged as 1\n","- PAN_FLAG: if pan was shared by the customer then flagged as 1\n","- VOTERID_FLAG: if voter id was shared by the customer then flagged as 1\n","- DRIVING_FLAG: if DL was shared by the customer then flagged as 1\n","- PASSPORT_FLAG: if passport was shared by the customer then flagged as 1\n","\n","These are binary or boolean fields where a 1 means that some piece of personal information was provided by the customer and 0 means it was not.\n","We already dropped the MOBILENO_AVL_FLAG because the value was the same for all rows. \n","\n","Essentially these columns can be considered as categoricals so we can use our explore_categorical function to look at them!\n","\n","Let's have a look at 'AADHAR_FLAG'. An AADHAR number is a 12 digit personal id number provided to residents of India by the government"]},{"cell_type":"code","metadata":{"id":"rXTqb2FIajwF"},"source":["explore_categorical('AADHAR_FLAG')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RmzdFZi_ajwF"},"source":["Looks like people who didn't provide their AADHAR number defaulted more frequently at 25.6%!"]},{"cell_type":"markdown","metadata":{"id":"8Snt7VjFajwF"},"source":["## Conclusion\n","\n","- In this chapter, we have demonstrated some techniques to carry out basic exploratory analysis \n","- This is only scratching the surface\n","- Specific techniques used for exploration may be dependent on both the data and its context\n","- Spend some time now exploring the data further\n","- Combine these techniques with your own intuition to formulate some hypothesis as to why a particular person might default on their loan\n","- As always if you have made changes to the data you wish to carry forward, remember to save it!"]},{"cell_type":"code","metadata":{"id":"JOXw5Jn5ajwG"},"source":["loan_df.to_csv('../data/vehicle_loans_eda.csv')"],"execution_count":null,"outputs":[]}]}