{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Loan Prediction Machine Learning Model\n",
    "\n",
    "# Chapter 5 - Linear Classifiers\n",
    "\n",
    "### Load Data and Import Libraries\n",
    "\n",
    "- Notice that we have included two new modules from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df = pd.read_csv('../data/vehicle_loans_feat.csv', index_col='UNIQUEID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1 - Train/Test Split\n",
    "\n",
    "For the rest of this chapter, we will work through the steps of creating a simple linear classifier using Logistic Regression\n",
    "\n",
    "First let's remind ourselves of the variables we are dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.info()"
   ]
  },
  {
   "source": [
    "It is important that our classifier recognises categorical variables where appropriate\n",
    "\n",
    "Lets use the [dtypes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html) property to look at the variable types of our categorical feilds"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = ['MANUFACTURER_ID', 'STATE_ID', 'DISBURSAL_MONTH', 'DISBURSED_CAT', 'PERFORM_CNS_SCORE_DESCRIPTION', 'EMPLOYMENT_TYPE']\n",
    "loan_df[category_cols].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- We do not want to treat MANUFACTURER_ID, STATE_ID and DISBURSAL_MONTH as integers \n",
    "- We can encode our categorical columns with the [category](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df[category_cols] = loan_df[category_cols].astype('category')\n",
    "loan_df[category_cols].dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE \n",
    "\n",
    "- To keep our first model simple, select 6 variables including 'LOAN_DEFAULT' and 'DISBURSED_CAT'\n",
    "- Using these variables create a subset of loan_df and store it as a separate DataFrame loan_df_sml\n",
    "- HINT: Think about the results of your exploratory analysis, which variables might be good predictors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION\n",
    "\n",
    "- I have selected the following 6 columns, 'STATE_ID', 'LTV', 'DISBURSED_CAT', 'PERFORM_CNS_SCORE', 'DISBURSAL_MONTH', 'LOAN_DEFAULT'\n",
    "- You could have selected any five which you are interested in, so long as one of them is 'LOAN_DEFAULT' and you have 'DISBURSED_CAT' which we will use later in this chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_cols = ['STATE_ID', 'LTV', 'DISBURSED_CAT', 'PERFORM_CNS_SCORE', 'DISBURSAL_MONTH', 'LOAN_DEFAULT']\n",
    "\n",
    "loan_df_sml = loan_df[small_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Let's have a quick look at our new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df_sml.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 233154 rows but now there are only 6 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df_sml.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Test Split\n",
    "\n",
    "- Before we fit (train) our basic linear model we need to split our data into training and test sets.\n",
    "- Training Data: used to fit the model to our specific data\n",
    "- Test Data: used to test the predictive power of the trained model  \n",
    "\n",
    "We can use the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from sklearn to create our training and test sets\n",
    "\n",
    "[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) has two required parameters \n",
    "\n",
    "- x: all of the rows and columns except the target variable \n",
    "- y: all of the rows but just the target variable column\n",
    "\n",
    "### EXERCISE\n",
    "\n",
    "- Create two variables x and y to match the required parameters for [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = loan_df_sml.drop(['LOAN_DEFAULT'], axis=1)\n",
    "y = loan_df_sml['LOAN_DEFAULT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should investigate the dimensions of x and y to make sure the above solution is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x has {0} rows and {1} columns\".format(x.shape[0], x.shape[1]))\n",
    "print(\"y has {0} rows\".format(y.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Looks like we have what need, now we can create our training/test data sets \n",
    "\n",
    "In addition to the required parameters of [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) we will also use \n",
    "- test_size: floating value between 0 and 1 indicating the size of the test set \n",
    "- random_state: integer value used for random seeding, allows for repeatability of the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) returns 4 output values \n",
    "\n",
    "- x_train: the training rows without the target variable \n",
    "- x_test: the test rows without the target variable \n",
    "- y_train: the training rows, target variable only \n",
    "- y_test: the test rows, target variable only \n",
    "\n",
    "Let's familiarize ourselves with this output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train has {0} rows and {1} columns\".format(x_train.shape[0], x_train.shape[1]))\n",
    "print(\"x_test has {0} rows and {1} columns\".format(x_test.shape[0], x_test.shape[1]))\n",
    "print(\"y_train has {0} rows\".format(y_train.count()))\n",
    "print(\"y_test has {0} rows\".format(y_test.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the number of rows and columns is what we would expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brilliant! All the train and test data has the correct columns \n",
    "\n",
    "Now let's use [value_counts](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) to check the distribution of the class variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Both the training and test set contain defaulted loans at 21.7%! \n",
    "\n",
    "We did not need to stratify due to the size of the dataset and the random nature of the sampling in [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2 - Variable Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time build our first binary classifier!\n",
    "\n",
    "First we create the model object using [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we [fit](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit) the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding \n",
    "\n",
    "Ok, looks like we made a mistake!\n",
    "\n",
    "The problem is that Logistic Regression, like most machine learning methods, does not know how to deal with string data\n",
    "\n",
    "We can use [pd.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) to one hot encode our categorical variables \n",
    "\n",
    "- Remember in lesson 1 we converted our categorical variables to the 'category' data type \n",
    "- If we didn't do this, variables like STATE_ID which contained integer representations of categories would be missed by [pd.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)\n",
    "- Then they would be incorrectly treated as continuous variables\n",
    "\n",
    "Lets one hot encode our small dataframe and assign it to a new variable 'loan_data_dumm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_dumm = pd.get_dummies(loan_df_sml, prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are passing three parameters to [pd.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)\n",
    "\n",
    "- loan_df_sml: our small dataframe which we want to encode \n",
    "- prefix_sep: prefix separator for the dummy variables, new columns will be created like 'CNS_SCORE_CAT_Low'\n",
    "- drop_first: drop the first dummy variable for each category \n",
    "\n",
    "HOLD ON! Why are we dropping the first dummy variable for each category?\n",
    "- Think about it\n",
    "- If we have 10 boolean variables indicating the presence of some category and there are no missing values \n",
    "- Then if the variable doesn't belong to one of 9 of the categories \n",
    "- It must belong to the 10th \n",
    "- So we can drop one of the dummy columns without losing any information\n",
    "- This helps to simplify the model and reduce the impact of correlated variables \n",
    "\n",
    "Let's look at the results of [pd.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_dumm.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Looks like we have dummy columns for our categoricals\n",
    "\n",
    "### EXERCISE \n",
    "\n",
    "- Take time to investigate the contents these new columns \n",
    "- Make sure you understand how [pd.get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) is transforming our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loan_data_dumm['STATE_ID_13'].value_counts())\n",
    "print(loan_data_dumm['STATE_ID_13'].value_counts(normalize=True))\n",
    "\n",
    "print(loan_data_dumm['DISBURSAL_MONTH_10'].value_counts())\n",
    "print(loan_data_dumm['DISBURSAL_MONTH_10'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 3 - Train and Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE \n",
    "\n",
    "- Recreate our training and test set using loan_data_dumm\n",
    "- Make sure the class distributions are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLUTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = loan_data_dumm.drop(['LOAN_DEFAULT'], axis=1)\n",
    "y = loan_data_dumm['LOAN_DEFAULT']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to [fit](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit) our model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! We are nearly there. We have successfully trained our model. But there is a warning we should take care of.\n",
    "\n",
    "The above warning is telling us that the LogisticRegression did not find a solution to fit our data within the maximum number of iterations. \n",
    "\n",
    "The specifics of this error are out of the scope of this course but the likely explanations are that our data is not actually linearly separable or that our selected columns and pre-processing do not provide enough information to make distinct separations on the data. \n",
    "\n",
    "Something to keep in mind, but for now, we can try to resolve the warning by increasing the maximum allowed iterations.\n",
    "\n",
    "The default value is 100, so let's try 200!\n",
    "\n",
    "*The waring may or may not appear depending on your system, if you don't see any problems you can skip this step*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(max_iter=200)\n",
    "logistic_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have successfully trained our model and we no longer see the convergence warning.\n",
    "\n",
    "Now we need to generate some predictions for our test set\n",
    "\n",
    "We pass our test features to the model to generate predictions, using [predict](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logistic_model.predict(x_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of predict is an array of 0s and 1s representing the loan default prediction\n",
    "\n",
    "This is great but we need some measure of model performance\n",
    "\n",
    "The [score](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score) function generates predictions and compares the predicted class with the actual class. The output is a floating-point number between 0 and 1 telling us the percentage of loans we correctly classified!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Looks like our model performed quite well, it predicted 78% of our test cases correctly.\n",
    "\n",
    "Don't get too excited, accuracy can be a misleading measure of model performance! The next chapter will look at other measures of model performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}